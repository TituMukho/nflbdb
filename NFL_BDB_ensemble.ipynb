{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this kernel\n\nMostly copied from bestpredict's kernel [Location EDA 8eb410][1]. I have applied the random forest (RF) regressor proposed in Dimension's kernel [[NFL] - [001]- [Feature selection]][2]. Let's see whether the reduced feature dimension will result in LB score improvement (V1-V3) and whether blending RF and neural network (NN) will improve the LB score (V4+). Please correct me if you have found any mistake. Thank you very much.\n\n## Changelog\n* **V5**: Try larger NN and elu activation.\n* **V4**: Since there is no improvement on LB score by discarding the original features, I try blending random forest and NN.\n* **V3**: Try threshold 0.2* mean\n* **V2**: Try threshold 0.5* mean\n* **V1**: Add feature selection based on the feature importance from a prefitted random forest regressor\n\n[1]: https://www.kaggle.com/bestpredict/location-eda-8eb410\n[2]: https://www.kaggle.com/coolcoder22/nfl-001-feature-selection"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:34.444922Z","start_time":"2019-11-06T13:27:30.768021Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nTRAIN_ABLE_FALSE=True\nif TRAIN_ABLE_FALSE:\n    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\nimport numpy as np\nimport pandas as pd\nimport sklearn.metrics as mtr\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization,LeakyReLU,PReLU,ELU,ThresholdedReLU,Concatenate\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.callbacks import Callback\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nTRAIN_OFFLINE = False\n\n\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 150)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:34.450789Z","start_time":"2019-11-06T13:27:34.447583Z"},"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:37.305506Z","start_time":"2019-11-06T13:27:34.452843Z"},"trusted":true},"cell_type":"code","source":"# train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\nif TRAIN_OFFLINE:\n    train = pd.read_csv('../input/train.csv', dtype={'WindSpeed': 'object'})\nelse:\n    train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n#train = pd.DataFrame(train.head(66000))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:37.336457Z","start_time":"2019-11-06T13:27:37.308386Z"},"trusted":true},"cell_type":"code","source":"outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:38.130612Z","start_time":"2019-11-06T13:27:38.110539Z"},"trusted":true},"cell_type":"code","source":"def strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x/15))\n    except:\n        return \"nan\"\ndef preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions for anchoring offense moving left from {0,0}"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:27:38.156575Z","start_time":"2019-11-06T13:27:38.132416Z"},"trusted":true},"cell_type":"code","source":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return 120.0 - x_coordinate\n        else:\n            return x_coordinate\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return 10.0 + yardline\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return 60.0 + (50 - yardline)\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n\n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n\n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return new_yardline\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return df\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n        return carriers\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n\n        return player_distance\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n        return defense\n    \n    def rusher_features(df):\n        \n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Dir', 'S', 'A', 'X', 'Y','PlayerWeight']]\n        rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS', 'RusherA', 'RusherX', 'RusherY', 'RusherWeight']\n        \n        radian_angle = (90 - rusher['RusherDir']) * np.pi / 180.0\n        v_horizontal = np.abs(rusher['RusherS'] * np.cos(radian_angle))\n        v_vertical = np.abs(rusher['RusherS'] * np.sin(radian_angle)) \n        \n        rusher['v_horizontal'] = v_horizontal\n        rusher['v_vertical'] = v_vertical\n        rusher['momentum'] = rusher['RusherA']*rusher['RusherWeight']\n        rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS','RusherA', 'RusherX', 'RusherY','RusherWeight','v_horizontal', 'v_vertical','momentum']\n        \n        return rusher\n\n\n    def static_features(df):\n        \n        \n        add_new_feas = []\n\n        ## Height\n        df['PlayerHeight_dense'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1])) \n        add_new_feas.append('PlayerHeight_dense')\n\n        ## Time\n        df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n        df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        add_new_feas.append('TimeDelta')\n        df['PlayerBirthDate'] =df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n        ## Age\n        seconds_in_year = 60*60*24*365.25\n        df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n        add_new_feas.append('PlayerAge')\n\n        ## WindSpeed\n        df['WindSpeed_ob'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n        df['WindSpeed_dense'] = df['WindSpeed_ob'].apply(strtofloat)\n        add_new_feas.append('WindSpeed_dense')\n\n        ## Weather\n        df['GameWeather_process'] = df['GameWeather'].str.lower()\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n        df['GameWeather_dense'] = df['GameWeather_process'].apply(map_weather)\n        add_new_feas.append('GameWeather_dense')\n#         ## Rusher\n#         train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n#         train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n#         temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n#         train = train.merge(temp, on = \"PlayId\")\n#         train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n        ## dense -> categorical\n#         train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n#         train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n#         train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n#         train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n        # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n        # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n        # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n        ## Orientation and Dir\n        df[\"Orientation_ob\"] = df[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n        df[\"Dir_ob\"] = df[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n        df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n        df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n        add_new_feas.append(\"Dir_sin\")\n        add_new_feas.append(\"Dir_cos\")\n\n        ## diff Score\n        df[\"diffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n        add_new_feas.append(\"diffScoreBeforePlay\")\n        \n        Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n        df['Turf'] = df['Turf'].map(Turf)\n        df['Turf_flag'] = df['Turf'].apply(lambda x: 1 if x == 'Artificial' else 0)\n        add_new_feas.append(\"Turf_flag\")\n        \n    \n        static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Distance','DefendersInTheBox']].drop_duplicates()\n#         static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n        static_features.fillna(-999,inplace=True)\n    \n        return static_features\n    \n    def cat_features(df):\n        \n        cat = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','OffenseFormation','Temperature','Humidity','Down','Quarter']]\n        cat['OffenseFormation'] = cat['OffenseFormation'].fillna('EMPTY')\n        replace_values = {'' : 'EMPTY', 'WILDCAT' : 'EMPTY', 'ACE' : 'EMPTY'}                                                                                          \n        cat = cat.replace({\"OffenseFormation\": replace_values})\n        \n        cat['OffenseFormation_shotgun'] = cat['OffenseFormation'].apply(lambda x: 1 if x == 'SHOTGUN' else 0)\n        \n        cat['Down_1'] = cat['Down'].apply(lambda x: 1 if x == 1 else 0)\n        cat['Down_2'] = cat['Down'].apply(lambda x: 2 if x == 2 else 0)\n        cat['Down_3'] = cat['Down'].apply(lambda x: 3 if x == 3 else 0)\n        cat['Down_4'] = cat['Down'].apply(lambda x: 4 if x == 4 else 0)\n        \n        cat['Quarter_1'] = cat['Quarter'].apply(lambda x: 1 if x == 1 else 0)\n        cat['Quarter_2'] = cat['Quarter'].apply(lambda x: 2 if x == 2 else 0)\n        cat['Quarter_3'] = cat['Quarter'].apply(lambda x: 3 if x == 3 else 0)\n        cat['Quarter_4'] = cat['Quarter'].apply(lambda x: 4 if x == 4 else 0)\n        \n        \n        cat['Temperature'] = cat['Temperature'].fillna(cat['Temperature'].mean())\n        \n        #cat[\"Quarter_ob\"] = cat[\"Quarter\"].astype(\"object\")\n        #cat[\"Down_ob\"] = cat[\"Down\"].astype(\"object\")\n        \n        #cat = pd.concat([cat,pd.get_dummies(cat['OffenseFormation'], prefix='OffenseFormation')],axis=1)\n#         cat = pd.concat([cat,pd.get_dummies(cat['Quarter_ob'], prefix='Quarter_ob')],axis=1)\n#         cat = pd.concat([cat,pd.get_dummies(cat['Down_ob'], prefix='Down_ob')],axis=1)\n        \n        #cat.drop(['OffenseFormation','Quarter','Down','Down_ob','Quarter_ob'], axis = 1, inplace = True)\n        cat.drop(['OffenseFormation','Down','Quarter'], axis = 1, inplace = True)\n        \n        return cat\n\n\n    def combine_features(relative_to_back, defense,rushing, static,cat, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,rushing,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,cat,on=['GameId','PlayId'],how='inner')\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        return df\n    \n    yardline = update_yardline(df)\n    df = update_orientation(df, yardline)\n    back_feats = back_features(df)\n    rel_back = features_relative_to_back(df, back_feats)\n    def_feats = defense_features(df)\n    rush_feats = rusher_features(df)\n    static_feats = static_features(df)\n    cat_feats = cat_features(df)\n    basetable = combine_features(rel_back, def_feats,rush_feats,static_feats,cat_feats, deploy=deploy)\n\n    return basetable","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.301052Z","start_time":"2019-11-06T13:27:38.158256Z"},"trusted":true},"cell_type":"code","source":"%time train_basetable = create_features(train, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_basetable.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_basetable.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's split our data into train/val"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.332475Z","start_time":"2019-11-06T13:31:22.303336Z"},"trusted":true},"cell_type":"code","source":"X = train_basetable.copy()\nyards = X.Yards\n\ny = np.zeros((yards.shape[0], 199))\nfor idx, target in enumerate(list(yards)):\n    y[idx][99 + target] = 1\n\nX.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_ori = list(X.columns)\n\nfeatures_interact = ['interaction_Dir_sin_momentum',\n'interaction_Dir_sin_def_min_dist',\n'interaction_X_DefendersInTheBox_vs_Distance',\n'interaction_Dis_Dir_sin',\n'interaction_num_DB_momentum',\n'interaction_PlayerWeight_back_from_scrimmage',\n'interaction_S_def_min_dist',\n'interaction_S_Dir_sin',\n'interaction_num_DB_Dir_sin',\n'interaction_momentum_max_dist',\n'interaction_S_mean_dist',\n'interaction_Distance_max_dist',\n'interaction_num_DB_S',\n'interaction_Distance_mean_dist',\n'interaction_Dis_momentum',\n'interaction_JerseyNumber_momentum',\n'interaction_JerseyNumber_back_from_scrimmage',\n'interaction_PlayerAge_back_from_scrimmage',\n'interaction_momentum_mean_dist',\n'interaction_num_DL_X',\n'interaction_Y_back_from_scrimmage',\n'interaction_PlayerAge_mean_dist',\n'interaction_Dis_def_min_dist',\n'interaction_num_QB_X',\n'interaction_Y_Dir_sin',\n'interaction_max_dist_back_from_scrimmage',\n'interaction_num_QB_momentum',\n'interaction_Distance_PlayerAge',\n'interaction_S_momentum',\n'interaction_momentum_std_dist',\n'interaction_Distance_Dir_sin',\n'interaction_Distance_momentum',\n'interaction_std_dist_back_from_scrimmage',\n'interaction_num_OL_X',\n'interaction_mean_dist_back_from_scrimmage',\n'interaction_num_QB_back_from_scrimmage',\n'interaction_momentum_PlayerHeight_dense',\n'interaction_num_OL_back_from_scrimmage',\n'back_from_scrimmage',\n'interaction_num_OL_momentum']\n\n# creating a list \nlist1 = ['interaction_momentum_PlayerHeight_dense', 'interaction_num_QB_back_from_scrimmage', 'interaction_JerseyNumber_back_from_scrimmage', 'interaction_num_OL_back_from_scrimmage', 'interaction_num_DB_S', 'interaction_num_DB_momentum', 'interaction_JerseyNumber_momentum', 'interaction_PlayerWeight_back_from_scrimmage', 'interaction_num_OL_momentum', 'interaction_num_DB_Dir_sin', 'interaction_X_DefendersInTheBox_vs_Distance', 'interaction_num_DL_X', 'interaction_num_QB_momentum', 'interaction_num_OL_X', 'interaction_num_QB_X']  \nfor i in list1:\n    features_interact.remove(i)\n\nfinal_features = features_ori + features_interact\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_A = X.columns\nfeatures_B = X.columns\ninteraction = list()\nfor i in range(0,len(features_A)):\n    for j in range(0,len(features_B)):\n        if i > j:\n            X['interaction'+\"_\"+str(features_A[i])+\"_\"+str(features_A[j])] = X[features_A[i]] * X[features_B[j]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[final_features]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.352690Z","start_time":"2019-11-06T13:31:22.334326Z"},"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's build NN and Random Forest Regressor"},{"metadata":{},"cell_type":"markdown","source":"Below class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n<br></br>\nBelow early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.386553Z","start_time":"2019-11-06T13:31:22.379178Z"},"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport keras.backend as K\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\nimport codecs\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import f1_score\n\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate CRPS score\ndef crps_score(y_prediction, y_valid, shape=X.shape[0]):\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_prediction, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * shape)\n    crps = np.round(val_s, 6)\n    \n    return crps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NN"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:31:22.395056Z","start_time":"2019-11-06T13:31:22.388490Z"},"trusted":true},"cell_type":"code","source":"def get_nn(x_tr, y_tr, x_val, y_val, shape):\n    K.clear_session()\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(1024, input_dim=X.shape[1], activation='elu')(inp)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512, activation='elu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='elu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n#     x = Dense(256, activation='elu')(x)\n#     x = Dropout(0.5)(x)\n#     x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=10)\n\n    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n\n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=120, batch_size=bsz,verbose=1)\n    model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=shape)\n\n    return model,crps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n\n# increase the n_estimators (50 -> 64) to see if this improves CV\ndef get_rf(x_tr, y_tr, x_val, y_val, shape):\n    model = RandomForestRegressor(bootstrap=False, max_features=0.3, min_samples_leaf=15, \n                                  min_samples_split=8, n_estimators=64, n_jobs=-1, random_state=42)\n    model.fit(x_tr, y_tr)\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=shape)\n    \n    return model, crps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:37:42.061299Z","start_time":"2019-11-06T13:31:22.396693Z"},"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\n\nloop = 2\nfold = 5\n\noof_nn = np.zeros([loop, y.shape[0], y.shape[1]])\noof_rf = np.zeros([loop, y.shape[0], y.shape[1]])\n\nmodels_nn = []\ncrps_csv_nn = []\n\nmodels_rf = []\ncrps_csv_rf = []\n\ns_time = time.time()\n\nfor k in range(loop):\n    kfold = KFold(fold, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        print(\"-----------\")\n        print(f'Loop {k+1}/{loop}' + f' Fold {k_fold+1}/{fold}')\n        print(\"-----------\")\n        tr_x, tr_y = X[tr_inds], y[tr_inds]\n        val_x, val_y = X[val_inds], y[val_inds]\n        \n        # Train NN\n        nn, crps_nn = get_nn(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0])\n        models_nn.append(nn)\n        print(\"the %d fold crps (NN) is %f\"%((k_fold+1), crps_nn))\n        crps_csv_nn.append(crps_nn)\n        \n        # Train RF\n        rf, crps_rf = get_rf(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0])\n        models_rf.append(rf)\n        print(\"the %d fold crps (RF) is %f\"%((k_fold+1), crps_rf))\n        crps_csv_rf.append(crps_rf)\n        \n        #Predict OOF\n        oof_nn[k, val_inds, :] = nn.predict(val_x)\n        oof_rf[k, val_inds, :] = rf.predict(val_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crps_oof_nn = []\n\ncrps_oof_rf = []\n\nfor k in range(loop):\n    crps_oof_nn.append(crps_score(oof_nn[k,...], y))\n    #crps_oof_lgbm.append(crps_score(oof_lgbm[k,...], y))\n    crps_oof_rf.append(crps_score(oof_rf[k,...], y))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:37:42.068378Z","start_time":"2019-11-06T13:37:42.063981Z"},"trusted":true},"cell_type":"code","source":"print(\"mean crps (NN) is %f\"%np.mean(crps_csv_nn))\n# print(\"mean crps (LGBM) is %f\"%np.mean(crps_csv_lgbm))\nprint(\"mean crps (RF) is %f\"%np.mean(crps_csv_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"mean OOF crps (NN) is %f\"%np.mean(crps_oof_nn))\n# print(\"mean OOF crps (LGBM) is %f\"%np.mean(crps_oof_lgbm))\nprint(\"mean OOF crps (RF) is %f\"%np.mean(crps_oof_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Blending Weight Optimisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def weight_opt(oof_nn, oof_rf, y_true):\n    weight_nn = np.inf\n    best_crps = np.inf\n    \n    for i in np.arange(0, 1.01, 0.05):\n        crps_blend = np.zeros(oof_nn.shape[0])\n        for k in range(oof_nn.shape[0]):\n            crps_blend[k] = crps_score(i * oof_nn[k,...] + (1-i) * oof_rf[k,...], y_true)\n        if np.mean(crps_blend) < best_crps:\n            best_crps = np.mean(crps_blend)\n            weight_nn = round(i, 2)\n            \n        print(str(round(i, 2)) + ' : mean crps (Blend) is ', round(np.mean(crps_blend), 6))\n        \n    print('-'*36)\n    print('Best weight for NN: ', weight_nn)\n    print('Best weight for RF: ', round(1-weight_nn, 2))\n    print('Best mean crps (Blend): ', round(best_crps, 6))\n    \n    return weight_nn, round(1-weight_nn, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_nn, weight_rf = weight_opt(oof_nn, oof_rf, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time for the actual submission"},{"metadata":{},"cell_type":"markdown","source":"## Define Prediction Function"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"def predict(x_te, models_nn, models_rf, weight_nn, weight_rf):\n    model_num_nn = len(models_nn)\n    model_num_rf = len(models_rf)\n    for k,m in enumerate(models_nn):\n        if k==0:\n            y_pred_nn = m.predict(x_te, batch_size=1024)\n            y_pred_rf = models_rf[k].predict(x_te)\n        else:\n            y_pred_nn += m.predict(x_te, batch_size=1024)\n            y_pred_rf += models_rf[k].predict(x_te)\n            \n    y_pred_nn = y_pred_nn / model_num_nn\n    y_pred_rf = y_pred_rf / model_num_rf\n    \n    return weight_nn * y_pred_nn + weight_rf * y_pred_rf","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-11-06T13:37:42.077763Z","start_time":"2019-11-06T13:37:42.070691Z"},"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"%%time\nif  TRAIN_OFFLINE==False:\n    from kaggle.competitions import nflrush\n    env = nflrush.make_env()\n    iter_test = env.iter_test()\n\n    for (test_df, sample_prediction_df) in iter_test:\n        basetable = create_features(test_df, deploy=True)\n        \n        basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n        \n        features_A = basetable.columns\n        features_B = basetable.columns\n        interaction = list()\n        for i in range(0,len(features_A)):\n            for j in range(0,len(features_B)):\n                if i > j:\n                    basetable['interaction'+\"_\"+str(features_A[i])+\"_\"+str(features_A[j])] = basetable[features_A[i]] * basetable[features_B[j]]\n\n        basetable = basetable[final_features]\n        \n        scaled_basetable = scaler.transform(basetable)\n\n        y_pred = predict(scaled_basetable, models_nn, models_rf, weight_nn, weight_rf)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n        preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n        env.predict(preds_df)\n\n    env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}